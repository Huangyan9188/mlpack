MLPACK is the first comprehensive scalable machine learning library.
Developed by the Fundamental Algorithmic and Statistical Tools
laboratory (FASTlab), MLPACK and its core functions library FASTlib
are the much needed filling of an existing void. Previously,
researchers had to either (a) settle for poorly-scaling collections of
methods implemented for academic purposes, (b) hunt down the often
difficult to find and difficult to apply yet fast code writen by
algorithms' developers, or (c) reimplement solutions to their specific
analysis problems from scratch. With MLPACK, we offer a fourth option,
in which researchers may find all the methods they need designed
favoring both speed and usability.

1. CONTENTS
-----------

MLPACK currently includes the following algorithms:

- allknn - A dual tree based $k$-nearest neighbor classifier using
kd-trees.

- allnn - A dual-tree based $k$-nearest neighbor classifier using
kd-trees, optimized for $k = 1$.

- fastica - Implements the FastICA Algorithm for Independent Component
Analysis using fixed-point optimization with various
independence-minded contrast functions.

- hmm - Implements 3 types of Hidden Markov Models: discrete, gaussian
and mixture of gaussians.

- infomax_ica - Implements the Information Maximisation algorithm for
Independent Component Analysis.

- kalman - Implements of the Kalman filter ensuring the positive
definiteness of the error covariance matrices by using QR and Cholesky
factorizations in both the measurement and time update steps.

- kde - Implements the following versions of kernel density
estimation: Using depth first dual tree, multidimensional fast fourier
transform, multidimensional fast gaussian transform and
multidimensional improved fast gaussian transform.

- mog - Implements parametric estimation of a mixture of Gaussians
using two different loss functions - maximum likelihood and the L2
error.

- naive_bayes - Implements the Naive Bayes Classifier.

- optimization - Implements two optimizers - The Nelder-Mead algorithm
and the Quasi-Newton algorithm.

- series_expansion - Implements the series expansion needed for the
fast $N$-body algorithm. Gaussian series expansion in $O(D^p)$ and
$O(p^D)$ are implemented. 

- svm - Implements the Support Vector Machine classifier and
regression. Includes the Sequential Minimial Optimization algorithm.

All algorithms are available in both executable and linkable form.
[More...]

2. HOWTO
--------

2.1. Quick start
----------------

1. Extract the tar/gzipped file, mlpack-0.1-distribution.tar.gz.

2. After this, you will need to make sure your environment variables
are set up properly. Simply add $FASTLIBPATH/script into your $PATH
environment variable. First find out what shell you are using by
typing

echo $0

and it will be bash, ksh, csh, or tcsh. If you are using the bash or
ksh shell, you should add this to your ~/.bashrc (for bash) or
~/.kshrc (for ksh), or ~/.profile if the other doesn't exist,
substituting $FASTLIBPATH accordingly:

export PATH="$FASTLIBPATH/script:$PATH"

If you are using csh or tcsh, put the following in your ~/.cshrc file:
setenv PATH "$FASTLIBPATH/script:""$PATH"

Close your terminal and re-open it. Check to see if FASTlib is working
by typing:

fl-build # that is lowercase "FL-BUILD"

It should give you the help message for FASTlib's build system. If it
doesn't, type:

echo $PATH

and make sure the $FASTLIBPATH/script is there and is spelled exactly
correctly. Try typing the export or setenv command by hand and see if
it starts working afterwards. Consult your friend who knows Unix when
necessary.

3. Now, change into your $FASTLIBPATH/mlpack by typing:

cd $FASTLIBPATH/mlpack

4. Compile all of the algorithms in mlpack by typing:

fl-build-all --mode=fast --recursive

Note that this will initially ask you to specify where to download
BLAS and LAPACK; we recommend choosing the option 1 for both (to
download and install from Netlib website). Option 2 tries to use the
preinstalled versions on the user's machine, but we did not have
success using this option:

First time installing BLAS, Here are your options: 

1)Press 1 if you want fastlib to download and install it from Netlib
website

2)Press 2 if you think you have a better version already installed
press 2
  You will be asked to give the full path along with the library name
(/path/libexample.a)
  if after giving the path you realize that it is wrong or it doesn't
work
  delete the $instalation_dir/fastlib/lapack.lock file and build your
code again Give me your choice now:

Now I will download BLAS from netlib.org
Generating a blas.lock file, if you want to reinstall differently delete it

First time installing LAPACK, Here are your options: 1)Press 1 if you
want fastlib to download and install it from Netlib website 2)Press 2
if you think you have a better version already installed press 2
  You will be asked to give the full path along with the library name
(/path/libexample.a)
  if after giving the path you realize that it is wrong or it doesn't work
  delete the $instalation_dir/fastlib/lapack.lock file and build your
code again

Give me your choice now:

Bascially, entering both options will create the two lock files,
blas.lock and lapack.lock.

CAUTION: If the user wants to recompile/reinstall BLAS/LAPACK, then
he/she would have to delete blas.lock and lapack.lock files.



2.2. Using the FASTlib Build Tool
---------------------------------

Underneath the Makefile under $FASTLIBPATH/mlpack directory, the
building is done via the fl-build tool, which stands for FASTlib
build. This tool reads through very short files which just have a list
of sources (.cc files), headers (.h files), and other sub-packages it
depends on, and produces a Makefile, which it runs automatically.

There are a handful of compilation modes supported by fl-build,
specified by the --mode=mode parameter. Each mode has a use, and
enables certain flags:

* verbose: tracking the execution of a program when it's infeasible to
step through manually. disables optimizations, enables printing of
verbosity messages

* debug: allow best use with gdb for tracking bugs. disables
optimization, enables all debug checks, enables highest level of gdb.

* check (default mode): regular development. enables code
optimizations and leaves in debug checks, at a 25% or so penalty. gdb
symbols are compiled in but may be inaccurate due to optimizations.

* fast: timing runs, for the fairest timing comparisons. debug symbols
still enabled but may be inaccurate.

* unsafe: optimizations that might alter correctness, and often
will slow the program down.

* profile: speed profiling. compile with --mode=profile, run your
program, and run gprof ./binaryfile | less to see what the bottleneck
is.

Using fl-build, you can compile each algorithm individually. Each
directory has a file called build.py, which specifies the various
"librule"s and "binrule"s. Building a "librule" makes the library
files that may be linked against other libary/binary files.

To add custom flags, add --cflags. To get increased performance on
Pentium 4 and define a macro called COAGULATE for the dual-tree KDE
implementation under $FASTLIBPATH/mlpack/kde directory, you would use:

fl-build dualtree_kde_bin --mode=fast --cflags="-march=pentium4
-DCOAGULATE"

2.3. How to run MLPACK
----------------------

Following the steps in Seciton 2.1 will populate each directory with
all of the symbolic links to the binary files.

For example, take dualtree_kde_bin binary file under
$FASTLIBPATH/mlpack/kde directory. Change directory into it and typing
the following:

./dualtree_kde_bin --help

brings up the parameters that can be used, "--data" and "--query", and
a submodule that is used to specify parameters that are specific to
kernel density estimation algorithm. Typing the following:

./dualtree_kde_bin --help=kde

brings up more parameter options you can use for specifying how the
algorithm can be run: by specifying the parameters under "--kde/".

Foe example, we can run KDE by typing the following in one line:

./dualtree_kde_bin --data=name_of_the_reference_dataset
                   --dwgts=name_of_the_reference_weight_dataset
                   --query=name_of_the_query_dataset 
                   --kde/kernel=gaussian
                   --kde/bandwidth=0.0130619
                   --kde/scaling=range 
                   --kde/multiplicative_expansion
                   --kde/fast_kde_output=fast_kde_output.txt
                   --kde/naive_kde_output=naive_kde_output.txt 
                   --kde/do_naive
                   --kde/relative_error=0.01

2.4. Linking to MLPACK 
----------------------
When doing the initial install, you can provide --prefix option to
optionally export the header files and the compiled library files
under an external directory. For example,

fl-build-all --mode=fast --recursive --prefix=/usr/fastlib_export

will install the required headers under
/usr/fastlib_export/include/fastlib2 and the required library files
under /usr/fastlib_export/lib. You can link against the generated
library and header files outside FASTlib system using the g++
compiler:

g++ external_program.cc /usr/fastlib_export/lib/*.a
-I/usr/fastlib_export/include/fastlib2 -L/usr/fastlib_export/lib

FUTURE PLANS
------------

MLPACK is growing quickly, and will soon also include:

- Affinity Propagation.

- C # versions of nearest neighbor.

- Convex optimization routines.

- Dual-tree nearest neighbor algorithm using Cover trees.

- Disk-based algorithms using memory-mapped file implementation.

- Euclidean Minimum Spanning Tree.

- Graphical model inference.

- Kernel Discriminant Analysis

- Local linear regression.

- Manifold learning algorithms (diffusion maps, Laplacian Eigenmaps,
LLE, Isomap).

- Nonnegative matrix factorization and many of its variants.

- Nonnegative SVM.

- Orthogonal range search.

- Ranking SVM.

- Sparse KDE using QP.


CONTACTS
--------
Please contact the following authors of the code for any problems:
Ryan Riegel         (rriegel@cc.gatech.edu)
Nikolaos Vasiloglou (nvasil@ieee.org)
Dongryeol Lee       (dongryel@cc.gatech.edu)
