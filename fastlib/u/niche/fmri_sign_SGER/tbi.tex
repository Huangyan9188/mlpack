\documentclass{article}

\author{Nishant Mehta}

\title{Recogning ASL in the Brains of TBI Patients}

\begin{document}

\maketitle

Traumatic brain injury (TBI) is capable of rendering its victims with a substantially reduced ability to execute motor movements, but it is often the case that their motor cortex continues to function properly and the messages simply do not travel along normal pathways to the rest of the body. A new communication avenue can provide these TBI patients with a considerable improvement in their quality of life and ability to function independently. BrainSign, a system for recognizing sign language in the brain, can provide precisely such an avenue. To recognize sign language in the brain, we will apply machine learning algorithms to the problem of gesture recognition in data from functional magnetic resonance imaging (fMRI) and electroencephalography (EEG). The combination of these two technologies offers data with both high spatial and high temporal resolution, and some previous work supports a principled fusion of the data provided by the two scanning modalities. The patterns themselves can be viewed as spatial activation maps evolving over brief periods of time. As an example, consider the pattern for a sign that involves the left hand moving into a fixed position and the right hand taping against the left hand repeatedly. Over a four second period, the neural activations will initially be significant for the area of the motor cortex corresponding to the left hand, and the neural activations for the right hand will be highly significant throughout the duration of the sign. The groundwork for highly promising machine learning methods for discriminating between such a videos of neural activation already exists.


\end{document}
