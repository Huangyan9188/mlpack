\documentclass{proposal}

\title{fMRI sign language motion pattern grant}



\begin{document}
\maketitle

\noindent{\bf C. Project Description}\\

\section{Introduction}

\subsection{Direct Brain Interfaces}

Nearly two million people in the US alone suffer from severe motor disabilities that render them incapable of communicating with the outside world \cite[]{ficke1992ddp, NABMRR1992, murray1997gmd, carter1997rmn}. Direct brain interfaces (DBIs) measure neural activation to provide a communication and control channel that is independent of muscle movement. To date, the best performance for a DBI communication system is 68 bit per minute (just over 8 characters per minute) \cite[]{gao2003bbe}, a rate attained using the Steady-State Visual Evoked Potential (SSVEP). While the progress made so far is notable, it pales in comparison to the transmission rates attained by signers and speakers.

\subsection{Sign Language Recognition from Brain Signals}

To date there has been little work in the way of recognizing signs and sign phrases using brain signals. Motor-related electroencephalography (EEG) research in the EEG community has focused on discriminating with coarse constrasts (e.g. left hand vs right hand vs left foot vs tongue). Much functional magnetic resonance imaging (fMRI), positron-emission tomography (PET), and event-related potential (ERP) work has focused on characterizing linguistic activation in the brain for several coarse categories. Only meaningless stimuli elicit a negative ERP wave between 400-500 ms after stimulus presentation (during the N400 window) \cite[]{supp2005_smr}. Regarding semantic ambiguity, a PET study has shown that among ambiguous words used as nouns, unambiguous verbs and ambiguous words used as verbs, and unambiguous nouns, only unambiguous nouns do not activate the left frontal operculum \cite[]{tranel2005_env}. ERP studies have shown that word class ambiguous words produce a greater frontal negativity, while ambiguous words presented in an unambiguous context may elicit greater positivity than unambiguous words \cite[]{lee2006_mme}. While \cite{dehaene1995_eec} found a left-lateralized positive ERP that is maximal over inferior frontal cortical sites and \cite{hjorth1975_oie, perrin1988_sss} found stronger electrocortical activity over bilateral motor cortices, to the contrary noun presentation has been found to produce greater ERPs in visual cortices \cite[]{hjorth1975_oie, perrin1988_sss}. Further, during sign language production, generation of verbs using the right or left hand alone produces similar activation of left inferior frontal and right cerebellum, indicating a semantic similarity independent of the particular articulator (hand/arm) used \cite[]{corina2003_llb}. \cite{emmorey2004_mis} found using PET that compared to naming tools, tool-related action produced higher activation in posterior right middle temporal gyrus, right angular gyrus, and occipital pole; they also found no significant activation difference when naming actions performed with a tool versus actions performed without a tool, indicating motor iconicity may not produce activation differences in the brain. Regarding production of locative classifier construction signs (i.e. signs that describe spatial relationships but do not name objects), a contrast between producing ASL nouns and locative classifier signs showed significant activation in the former case in left BA 45 (possibly part of Broca's area). This differential activation was not noticed when instead using English \cite[]{emmorey_broca_region_2006}.

New evidence, however, suggests that certain properties of movement may be reflected well in fMRI, such as a linear relationship between movement rate and fMRI activation \cite[]{rao1996rbf}. Additionally, neural events in the same cerebral region that are distanced by at least 4 seconds of each other have been shown to be separable using fMRI \cite[]{kim1997ltr} offering the possibility of using the fMRI time course for identifying long-duration ($\geq$ 4 s) events. These results suggest that fMRI may provide sufficient information for discriminating between long-duration events. To further increase discriminability, it is only natural to seek methods that can offer high precision spatiotemporal activation patterns. Previous work has been limited by an inability to study such patterns due to poor spatial resolution of EEG and poor temporal resolution of fMRI/PET.

\subsection{Time course of Sign Language Activation}

Treating the generating neural activity of sign language as including time course of motor activation, there is a fundamental need for work that combines the activity localization ability of fMRI with the activity time-locking ability of EEG. Inherent in boosting the spatial resolution of EEG is a need to localize generating sources of electrical activity accurately and somewhat precisely in the three-dimensional brain. While solving this inverse problem (taking a 2D manifold of activation and predicting the 3D map of source activation) is not a well-posed problem because of the non-uniqueness of solutions, substantial work has used anatomical priors to reduce the complexity of the problem.

More recently, some researchers have had success in combining fMRI data with EEG data to obtain high-resolution spatiotemporal maps of neural activity. The idea is to constrain a source localization algorithm by using functional priors of activation derived from fMRI activation during the relevant activity. \cite{im2006tcm} developed a method for weighting functional prior data obtained from fMRI in accordance to how well the spatial activation areas match the areas predicted by source localization data that is not fMRI-constrained. One widely used method is to place dipoles at fMRI foci and optimize orientation and magnitude of the dipoles for each time instant, where the fMRI foci are obtained from stimuli presentation identical to EEG / magnetoencephalography (MEG) recording stimuli \cite[]{ahlfors1999sac}. Because of the large number of areas involved during language production, we may be more interested in cortical current density estimates; \cite{wagner2000fcd} used appropriate weighting of fMRI activation data to correctly calculate simulated cortical density. Further, \cite{dale2000dsp} also incorporated fMRI recorded during stimulus presentation into EEG/MEG source localization by the use of Bayesian statistics and and a rough approximation of the dependency between electrical activity and the hemodynamic response.




\subsection{Novel Experiment Design}

To accomplish our goals, we invoke a paradigm shift in fMRI analysis. We consider gesture differentiation using time series of fMRI slices. Similar to response to a blocked-task, but instead of accomplishing longer activation duration via repeated activation using the same stimulus/activity, we consider longer activation duration via a stimulus/activity spanning a long time window. One example of such a "long" activity is a sequence of gestures, rather than a single gesture. This differs from classical blocked-task, where activation builds in certain areas from repeated application of a stimulus that affects a certain cerebral region. In this case, we may be stimulating different cerebral regions with each atom of the sequence, but recognition still becomes statistically feasible because of evidence provided by single-trial fMRI work \cite[]{buckner1996dca}. An important question to answer is whether spatiotemporal fMRI activation maps of such temporal uncertainty provide well-separated events in the statistical identifiability sense (as testable by machine learning methods).

\subsection{Sign Language Direct Brain Interface}

To our knowledge, there has not been any work on developing a DBI system that recognizes sign language signs and phrases using fMRI or EEG. A critical property of such a system is portability; an EEG-based system is far more attractive from this criteria. Additionally, application of this research towards an interface for the mobility-challenged entails use of imagined movements rather than executed movements.


Imagined movements are expected to produce neural activations similar though lesser in magnitude to actual movements \cite[]{beisteiner1995mrm}. There is a large body of evidence supporting the visibility of imagined movements in EEG \cite[]{pfurtscheller1997mia, beisteiner1995mrm, lang1996eam}, and significant evidence also supports fMRI showing activation during imagined movement \cite[]{lotze1999aac}.

\section{Justification for SGER Support}

We are the first researchers to focus precisely on motor differences in fMRI activation patterns during signing. To our knowledge, no one has yet analyzed the fMRI time course of sign language phrases to identify temporal activation patterns that can discriminate between different phrases. Additionally, using EEG to discriminate between signs and phrases is uncharted territory that can offer extraordinary rewards for disabled and environmentally-constrained populations. Our proposed work on identifying motion patterns using fMRI and EEG data of the motion patterns also is new, and any discoveries in this area can contribute fundamentally towards a deeper understanding of motor planning/cognition. The impact of this research is to offer the target populations unmatched levels of information transmission to the rest of th world. Additionally, our use of the proposed long-duration-activity fMRI experiment design will lay the groundwork for other researchers to apply this design to countless other experiments to prove statistical correlations for new stimuli/activites with high statistical power.


\section{Research Approach}

Our approach strives to verify the signal discriminability of fMRI and EEG for multiple classes of motion categories, including single signs, sign phrases, motion patterns, and the imagined dual versions of these categories. All of the experiments will be performed first with actual movements and then with imagined movements. Prior to imaging/recording subjects during the imagined movement experiments, we will verify that the subjects' imagined movements produce motor cortex activation; this verification will be done using EEG focused at the motor cortex with electromyography (EMG) verifying that no actual movement is occurring.

A prerequisite to signing when lying supine on an fMRI bed is to sign comfortably when restrained by straps that mitigate head movement. Following \cite[]{culham2003vgg} we will minimize head movement by restricting shoulder movement and partially limit elbow movement using arm braces; it will be necessary to have subjects practice the signs under these conditions. In order to correct any movement artifacts picked up in the fMRI, e will make use of machine learning methods for movement artifact removal [GET CITATIONS FROM CHIP].

We first will record subjects signing individual signs in a single trial experiment design. These signs will be selected so that they span a set of key properties (left/right hand only, coarse/fine movement, individual finger movements) to maximize the possible offline analysis. In the next phase, we will record from a set of sign phrases, with the expectation that the longer duration of the activity will increase discriminability of the fMRI time course. Again, the set of sign phrases will be selected to span a set of key properties. The experimental protocol shares the long-activation duration of the blocked design protocol where a single stimulus presentation or activity is repeated numerous times in succession, except in this case the larger time block actually consists of a longer-duration activity. Activity duration for gesture sequences likely will be between 5 - 10 seconds. We take lead from evidence that single trial fMRI recording can provide sufficient statistical power for discriminating stimuli \cite[]{buckner1996dca}, and we expect substantially greater discrimination likelihood for sign phrases since they consist of multiple signs. We believe that the final fMRI experiment has not yet been studied and serves as a novel contribution to motor planning cognition. Subjects will first be trained to verify that they can produce the same motion patterns with their hands and feet. In this experiment, subjects will produce particular patterns of motion (e.g. for a \textit{rotation} pattern, hand rotation or foot rotation), and our analysis will apply machine learning algorithms to detect patterns in the fMRI time courses for particular motion patterns.

After exploring the spatiotemporal activation patterns in the fMRI, we will record subjects signing the same individual signs, phrases, and motion patterns using EEG. Our analysis will employ functional priors obtained from the fMRI experiment data, facilitating source localization of the scalp potentials to three-dimensional regions in the brain. This application of fMRI data to enhance high temporal resolution EEG data with high spatial resolution as well opens the door to high spatiotemporal pattern analysis of sign language and motion patterns. We will develop the first ever direct-brain interface that classifies sign phrases from EEG; this system will rely largely upon advanced machine learning time-series methods.


\section{Objectives}

The overall goal is to predict imagined gestures using fMRI and EEG. We endeavor to accomplish this goal in two phases. First, we will explore the utility of motion pattern information carried by fMRI and gauge the extent to which we can discriminate different gestures at different levels of complexity (single gestures vs phrases) from the fMRI data. Second, we will use the fMRI spatial activation (and possibly time course) information induced by gestures to constrain EEG source localization algorithms. We note that all of the objectives involve experimentation with both actual and imagined movements, the latter being fundamental for assisting disabled and environmentally-constrained individuals. These objectives can be enumerated as follows:

\begin{enumerate}
\item \textit{Characterize the discriminability of sign language using fMRI data} - Discover the extent to which single ASL gestures of varying complexity can be discriminated from fMRI. We will measure discriminability through use of signal trial fMRI recordings of gestures spanning a variety of criteria. We also will test a novel fMRI experiment design that considers statistical significance of certain activation time courses; this design can contribute to a system that differentiates ASL phrases (sequences of ASL gestures) using fMRI data. Finally, we will characterize the extent to which patterns in fMRI time course are common to particular large motion patterns independent of the appendage used (e.g. left hand vs right foot). Such a characterization to our knowledge has never been done.
\item \textit{Gesture discrimination using fMRI-informed EEG source localization} - Conduct the first known analysis of ASL recognition using EEG, by using functional priors obtained from the fMRI results to conduct constrained source localization of the EEG. We will apply the analysis to create the first known portable system that recognizes ASL recognition from brain signals.
\end{enumerate}

\section{Expected Significance and Impact on the Field}
This work will make large contributions towards the field of direct-brain interfaces. It will constitute the first DBI that provides an extremely high information tranmission rate, because the number of possible signs that may be expressed is not necessarily bounded. The framework will offer a powerful example of high spatiotemporal resolution pattern recognition for DBIs, and other researchers can benefit greatly by applying this combination of fMRI and EEG towards other communication/control problems (e.g. spatiotemporal localization can provide increased benefit for using event-related potentials (ERPs), as compared to simply using time course information).

Our work also has considerable potential contributions towards cognitive neuroscience, serving as the first comprehensive study of spatially co-located, cognitively orthogonal motor tasks. Some previous work has considered neural activation trends with respect to rate of motor movement \cite[]{rao1996rbf}, but there so far as not been a thorough analysis of different combination of muscles with varying magnitudes, speed, and motion patterns. Our analysis will directly lead to a more detailed understanding of motor planning and motor activations during sign language and many other motorically similar actions. The additional study of identifying neural activation patterns for particular classes of motion patterns will encourage further spatial pattern analysis. The use of long-duration activity recording will provide a model that can be applied to countless other experiments for increased statistical power.


\section{Broader Impacts}

This work can provide broad \textit{brain gesture} communication abilities for many people that work in mobility-restricted environments. Our particular focus on sign language in the brain can increase the pervasiveness and adoption of sign languages, assisting primary users of sign languages while simultaneously assisting disabled persons that can benefit from the new communication method. Our DBI should substantially increase communication bandwidth, surpassing by a wide margin the current best information capacity of a DBI, the 68 bits/min previously attained using SSVEP \cite[]{gao2003bbe}. Additionally, the collaboration entailed by this project will encourage cross-pollination of ideas between undergraduates and graduates from fields spanning cognitive neuroscienc, intelligent systems, statistics, and control systems design.


\section{Relation to Longer-term Goals of PI}

\section{Most Relevant Results from Prior NSF Support}

\section{Plan of Work}

Yes

\section{Educational Activities}

Teach kids about nuclear magnetic resonance and EEG, all of the exciting stuff

Have EEG recording sessions with the kids, ideally do this at a school for the deaf with the students signing while being recorded






\bibliography{bib}
\bibliographystyle{jponew}



\end{document}
