<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>



	<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1"><title>Neural Information Processing Systems Conference 2007</title>
	
	<link rel="SHORTCUT ICON" href="http://nips2007.confmaster.net/confKat_nips/NIPS2007/images/favicon.ico">
	<link rel="stylesheet" type="text/css" href="author_view_reviews_files/stylesheets_print_002.css">
	<link rel="stylesheet" type="text/css" href="author_view_reviews_files/stylesheets_print.css">
	<script src="author_view_reviews_files/js_functions.js" type="text/javascript">
	</script></head><body bgcolor="#ffffff">
<table border="0" cellpadding="0" cellspacing="1" width="750">
		<tbody><tr>
			<td width="5"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="5"></td>
			<td width="735"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="735"></td>
			<td width="15"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="15"></td>
		</tr><tr>
			<td></td>
			<td>
<!-- Content Area starts here ========================================================= -->

<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tbody><tr>
	<td class="TextContentHeadline">Review Feedback and Response</td>
</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="1" width="100%">
<tbody><tr>
	<td colspan="2"><br></td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2">
	<ul>
		<li> The
purpose of author feedback is to point out technical errors or
significant misunderstandings. it is not to dispute the opinions of the
reviewers, or to explain how criticisms can be addressed! </li>
                 <li> Do not expect replies to your feedback
in the final reviews. Rest assured that feedback identifying true flaws
or misunderstandings will be taken into account in final decisions. </li>
                 <li>
Please do not provide feedback explaining how you can address the
referees' concerns or criticisms. It is our assumption already that
concerns will be addressed in the final version. </li>
                 <li> Feedback should be brief and specific.
You will see three reviews. Target your feedback to specific reviewer
comments. For example: "The review says crucial formula x+y on page 5
is wrong. Note the formula given on page 5 is actually x+z, not x+y." </li>
                 <li>
Your job is to identify major misunderstandings, not to dispute the referees' criticisms or value judgements.
		</li>
                 <li>
Feedback is strictly limited in length to 250 words per review, no exceptions	</li>
         </ul>
         </td>
</tr>
<tr>
	<td colspan="2"><br></td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="100">&nbsp;Paper ID</td>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="300">1032&nbsp;</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="100">&nbsp;Paper authors</td>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="300">Ryan Riegel, Garrett Boyer, Alexander Gray&nbsp;</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="100">&nbsp;Paper title</td>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="300">A Mathematical Theory for Scalable Learning&nbsp;</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="100">&nbsp;Paper subtitle</td>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="300">&nbsp;</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="100">&nbsp;Preference</td>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="300">Research Paper</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="100">&nbsp;Keywords</td>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="300">Other Algorithms</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="100">&nbsp;Abstract</td>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="300">We present mathematical foundations for a highly successful<br>
algorithmic strategy that has resulted in the fastest algorithms for<br>
many machine learning methods and is broadly applicable to scaling<br>
many future methods up to large datasets.  We formalize for the first<br>
time a class of computational problems which are common in machine<br>
learning, called generalized N-body problems (GNP's), and<br>
provide a calculus for simplification of GNP's in various ways.  We<br>
then present a template generalized N-body algorithm applying<br>
to any GNP, which can be specialized to mathematically derive<br>
efficient problem-dependent algorithms using the calculus.  We<br>
demonstrate the use of this mathematical framework for deriving a fast<br>
algorithm for the recent affinity propagation method.<br>
</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="100">&nbsp;Average overall recommendation</td>
	<td class="TextContentNormal" bgcolor="#cccccc" valign="top" width="300">6.00&nbsp;</td>
</tr>
<tr>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="100">&nbsp;Download</td>
	<td class="TextContentNormal" bgcolor="#ffffff" valign="top" width="300"><a href="http://nips2007.confmaster.net/pages/download.php?File=NIPS2007_1032_a5ff7f1246fe9fdc14943e8a87c3e286.pdf&amp;Conf=NIPS2007&amp;PHPSESSID=5ecee2146248827fce6fde415618a431"><img src="author_view_reviews_files/icon_download.gif" alt="download file" title="download file" border="0" height="20" width="14"></a></td>
</tr>
<tr>
	<td colspan="2"><br></td>
</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="1" width="100%">
<tbody><tr>
	<td colspan="3"><br></td>
</tr>
<tr>
	<td colspan="3" bgcolor="#000000"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="100%"></td>
</tr>
<tr>
<td></td>
<td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion01.png" alt="Criterion01" title="Criterion01" border="0" height="100" width="15"></td><td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion02.png" alt="Criterion02" title="Criterion02" border="0" height="100" width="15"></td></tr>

<tr>
	<td class="TextTableTitle" align="left" bgcolor="#333333">&nbsp;</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">8</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">9</td>

</tr>

<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Comments to author(s)</strong><br>
The authors formalize a class of computational problems that are common
in machine learning and which they call "generalized n-body problems".
Such generalized n-body problems arise in machine learning when
algorithms explore interactions between pairs of data points, such as
in clustering and embedding. After presenting a framework for
describing such problems, they show how efficient divide-and-conquer
algorithms can be derived using their general-purpose method. In
addition to demonstrating their approach using two old problems, namely
computing two-point correlation and finding nearest neighbors, they
apply their approach to the recently-described affinity propagation
algorithm and achieve an extrapolated speedup of 300 over the naïve
implementation of affinity propagation, when applied to 1 million
3-dimensional data points in Euclidean space (although, this speedup
does depend on the dimensionality of the data points). The paper is
well-written, although overly-technical, and presents a sound and
demonstrably-powerful approach to an important problem.<br>
<br>
While I think this paper is quite appropriate for NIPS, my main concern
is that the presentation is quite complicated and this may turn people
off of using this as a general-purpose tool. In most cases, if a
machine learning researcher is analyzing a very large data set using an
algorithm that explores pair-wise interactions, he/she will come up
with an ad hoc way of pruning interactions based on a metric. The
method proposed in this paper is a formal way of doing this for a
general class of problems, but unless it can be communicated in a
relatively simple fashion, it is unlikely that readers will bother to
use this framework. I strongly urge the authors to think of ways to
simplify their method and their description of their method, so that it
is more accessible to readers.<br>
<br>
For starters, the section on the two examples is not very clear
(Section 2 and Figs 1&amp;2). Function tpc takes two arguments, but the
recursive call passes three arguments. It should be mentioned that the
location of the best split for tpc is easy to compute so that the
algorithm is really recursively deciding which dimension to split.
(This would help the reader understand why there isn&#8217;t any discussion
or pseudocode having to do with identifying the location of the split.)
The text talks about the two-point correlation of a data set X, but the
pseudocode makes decisions by comparing points from two sets X and Y.
All of this should be cleared up (for allnn as well), so that the
reader can easily understand the examples.<br>
<br>
It is impressive that the authors were able to apply their technique to
such a recently-published algorithm as affinity propagation (which
appeared in Feb 2007). This is a testament to the validity of their
claim that their method can be applied to various machine learning
problems and in a straightforward manner. It would be valuable if the
authors could post their software for affinity propagation and other
algorithms on the internet. Also, since the proposed method assumes the
similarities are metric, it would be helpful to compare the method with
a version of affinity propagation that only sends a message between a
pair of points if the points are not too far apart. Determining this is
not trivial (thus the interest in the proposed method), but for
comparison purposes, the authors could come up with a simple method and
compare the resulting version of affinity propagation to their
technique. Fig 5 is very convincing. It would be helpful to show plots
for different numbers of dimensions, so the reader gets a sense for how
the gains depend on the dimensionality of the data.<br>
<br>
The authors say that "data sets with high intrinsic dimensionality
diminish the asymptotic gains of our algorithm". It would be useful to
know whether good gains can still be achieved in practice if the data
are projected to a lower-dimensional subspace for the purpose of
computing the bounds used by the method. <br>
<br>
I think the authors would benefit by toning down their language a bit.
I'm not sure they have "a mathematical theory for scalable
learning""and I'm also not sure the have introduced a new "calculus".
The paper would be more solid and better appreciated if (in addition to
simplifying and clarifying the exposition) more conservative language
were used, eg, a title like "Deriving efficient algorithms for n-body
machine learning techniques" or somesuch.<br>
<br><br>
	</td>
</tr>
<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Summary of review</strong><br>
The authors describe a general framework and method for deriving
algorithms that solve the generalized n-body problem, instances of
which include clustering and embedding via comparisons between pairs of
data points. The authors show that their method can be applied to
different problems and can yield algorithms that are orders of
magnitude faster than previously-published algorithms. This is one of
the best papers I reviewed.<br><br>
	</td>
</tr>
<tr>
	<td colspan="3"><br></td>
</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="0" width="100%">

<tbody><tr>
	<td class="TextContentNormal" colspan="2"><br></td>
</tr>
<tr>
	<td class="TextAlert" bgcolor="#ffffff">Authors response by Garrett Boyer (2007-07-24 01:09:20) to review</td>
	<td class="TextAlert" align="right" bgcolor="#ffffff">&nbsp;</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff"></td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>We
regret the lack of space for detailed responses to all the insightful
points in the reviewer's much-appreciated in-depth
analysis, though some appear across the responses to all three
reviewers. The consensus appears that the main difficulty with the
paper is its understandability, rather than the significance, which
presents for the first time a general way of creating efficient
algorithms for a wide class of computations appearing in many machine
learning methods, both classical and future (more or less anything
involving interactions between pairs of points), much as general
inference schemes do for the large set of machine learning methods
which can be posed as graphical models. (Though the suggestion
to use more qualified statements is well-taken.) We are sensitive to
the reviewer's point that if the presentation is inaccessible,
researchers will continue to resort to various ad hoc approximations
with magic tuning parameters and unknown errors (indeed, the ones
suggested by the reviewer are typical, and comparing them in a longer
exposition is a good idea). We included many proofs to establish rigor,
but after reading the reviewers' reactions, we now realize we should
have devoted more space to the examples in Section 2, making the
algorithm pseudocode clearer (addressing the valid confusions raised by
the reviewer) and including several pictures we know will help. This
can easily be done by removing all the simpler proofs. We could then
also address the reviewer's other good points.</p>
</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff">Review Evaluation: ++ outstanding review</td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>We highly appreciate the reviewer's attention to detail.</p>
</td>

</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="1" width="100%">
<tbody><tr>
	<td colspan="3"><br></td>
</tr>
<tr>
	<td colspan="3" bgcolor="#000000"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="100%"></td>
</tr>
<tr>
<td></td>
<td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion01.png" alt="Criterion01" title="Criterion01" border="0" height="100" width="15"></td><td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion02.png" alt="Criterion02" title="Criterion02" border="0" height="100" width="15"></td></tr>

<tr>
	<td class="TextTableTitle" align="left" bgcolor="#333333">&nbsp;</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">3</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">6</td>

</tr>

<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Comments to author(s)</strong><br>
		<br>
The paper derives a mathematical theory for the so-called generalized N-body problem. <br>
<br>
I find the paper hard to follow, and don't understand the point of this
paper. Although there are many definitions, algorithms, and "theorems",
without putting them into appropriate context, it is difficult to
understand their implications. The experiments are too simplistic to
provide any value.<br>
<br><br>
	</td>
</tr>
<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Summary of review</strong><br>
The author(s) should improve the readability of the paper, and try to
provide more convincing experiments and examples to justify the content.<br>
<br><br>
	</td>
</tr>
<tr>
	<td colspan="3"><br></td>
</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="0" width="100%">

<tbody><tr>
	<td class="TextContentNormal" colspan="2"><br></td>
</tr>
<tr>
	<td class="TextAlert" bgcolor="#ffffff">Authors response by Garrett Boyer (2007-07-24 01:19:35) to review</td>
	<td class="TextAlert" align="right" bgcolor="#ffffff">&nbsp;</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff"></td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>We
thank the reviewer for the very helpful feedback. We appreciate the
reviewer's point regarding the clarity of the examples, for which we
apologize. We do feel this is correctable, however, as noted in the
response to reviewer 1. We also regret not having the space to show
more comprehensive experimental results for the new algorithm derived
for affinity propagation. However, as noted by reviewer 1, the fast
algorithm for affinity propagation is actually a very secondary point
of the paper, only there to illustrate that this theory is sufficiently
powerful that we were able to take a very recent machine learning
method proposed (in this case, in February 07) and use our theory to
create a fast algorithm for it, literally in the same week in which we
had heard of it. The example also demonstrates the applicability of the
theory to the most modern methods, including one which is a fair bit
more complicated than, say, nearest neighbor or kernel estimation. In a
longer version of the paper, we can easily explore the algorithm on
further datasets, explore the effect of
dimensionality, etc. However, such in-depth studies are actually
performed in original works we cite when introducing examples. The
tree-based algorithms derived by the theory will have the same general
sorts of behaviors, including very good scaling with the number of
data, and scaling which is sensitive to the intrinsic (rather than
nominal) dimensionality of the data.</p>
</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff">Review Evaluation: 
- mediocre review</td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>The
authors would appreciate more detailed feedback, such as particular
points of confusion. Although the author admits not understanding the
purpose of the paper, we would appreciate know what the author believed
the point actually was. The tone is also unprofessional with
unnecessary invokation of loaded words.</p>
</td>

</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="1" width="100%">
<tbody><tr>
	<td colspan="3"><br></td>
</tr>
<tr>
	<td colspan="3" bgcolor="#000000"><img src="author_view_reviews_files/spacer.gif" alt="bild" border="0" height="1" width="100%"></td>
</tr>
<tr>
<td></td>
<td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion01.png" alt="Criterion01" title="Criterion01" border="0" height="100" width="15"></td><td class="TextTableTitle" align="right" bgcolor="#333333" width="15"><img src="author_view_reviews_files/image_criterion02.png" alt="Criterion02" title="Criterion02" border="0" height="100" width="15"></td></tr>

<tr>
	<td class="TextTableTitle" align="left" bgcolor="#333333">&nbsp;</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">6</td>
<td class="TextTableTitle" align="right" bgcolor="#333333" valign="top">5</td>

</tr>

<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Comments to author(s)</strong><br>
The authors introduce a general framework, called generalized N-body
problems (GNPs), which is applicable to a several machine learning
problems, and allows efficient solutions and implementation of
problem-dependent algorithms. The authors demonstrate that with the
affinity propagation clustering method.<br>
<br>
The paper is technically sound (though some proofs were omitted for
brevity, and some others are very simple algebra). The style used for
algorithms isn't particularly legible. The paper is significant and
original as it improves upon speed of a clustering algorithm and does
so in a generalized way that can be applied to other problems.<br>
<br>
Application of the GNPs to other algorithms would strengthen the paper significantly.<br>
<br><br>
	</td>
</tr>
<tr>
	<td colspan="3" class="TextTableRow" bgcolor="#ffffff" valign="top">
		<strong>Summary of review</strong><br>
This paper presents an interesting framework for scaling existing ML
algorithms to large scale problems. However, experimental results are
limited to Frey and Dueck's algorithm.<br><br>
	</td>
</tr>
<tr>
	<td colspan="3"><br></td>
</tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="0" width="100%">

<tbody><tr>
	<td class="TextContentNormal" colspan="2"><br></td>
</tr>
<tr>
	<td class="TextAlert" bgcolor="#ffffff">Authors response by Garrett Boyer (2007-07-24 01:21:57) to review</td>
	<td class="TextAlert" align="right" bgcolor="#ffffff">&nbsp;</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff"></td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>We
thank the reviewer for the very helpful feedback. We agree with the
point that more examples would improve the paper, both in terms of its
understability, and in terms of demonstrating the full power of the
theory. We were able to present three full examples of real algorithms
derivable from the theory (two old and one new), all of which are the
overall fastest methods for their respective well-known problems, while
still including proofs for all the mathematical statements. However, we
could possibly incorporate the reviewer's suggestion of demonstrating a
fast algorithm for a second new problem, which would take considerable
space, by addressing the second point of the reviewer by cutting out
all of the simpler proofs. (At the time of sumbission, we indeed had
fast algorithms for multiple new problems which we could have
described, as it turns out.) Doing so would free up half a page or
more, which could be used to either enrich the exposition of the
examples in Section 2, as mentioned in the response to reviewer 1, or
to present an algorithm for a second new problem in
addition to affinity propagation. It is unlikely we could do both,
given only 8 pages, unfortunately, since they would both be valuable
additions to the paper.</p>
</td>
</tr>
<tr>
	<td class="TextContentHeadline" colspan="2" bgcolor="#ffffff">Review Evaluation: 
+ good review</td>
</tr>
<tr>
	<td class="TextContentNormal" colspan="2" bgcolor="#ffffff"><p>Reviewer made significant effort to understand paper despite its overly technical nature, and provided useful feedback.</p>
</td>

</tr>
</tbody></table>
<!-- Content Area ends here ========================================================= -->
</td>
</tr>
<tr>
<td></td>
<td>
	<table class="TextFooterBlack" border="0" cellpadding="0" cellspacing="0" width="100%">
		<tbody><tr>
			<td align="left" width="400"><a href="http://www.confmaster.net/" target="_blank"><img src="author_view_reviews_files/confmaster_logo_invers.gif" title="ConfMaster.net" alt="ConfMaster.net" border="0" height="19" width="155"> &nbsp; The Conference Management System</a></td>
			<td align="right" valign="center" width="350"><a href="http://www.confmaster.net/" target="_blank">Copyright (C) www.ConfMaster.net, 2002-2007.</a></td>
	   </tr>
  </tbody></table>
</td>
</tr>
</tbody></table>
</body></html>